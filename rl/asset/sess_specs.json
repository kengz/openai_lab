{
    "dummy": {
        "problem": "CartPole-v0",
        "Agent": "dummy.Dummy",
        "Memory": "LinearMemory",
        "Policy": "EpsilonGreedyPolicy",
        "PreProcessor": "NoPreProcessor",
        "param": {}
    },
    "q_table": {
        "problem": "CartPole-v0",
        "Agent": "q_table.QTable",
        "Memory": "LinearMemory",
        "Policy": "EpsilonGreedyPolicy",
        "PreProcessor": "NoPreProcessor",
        "param": {
            "learning_rate": 0.01,
            "gamma": 0.99,
            "exploration_anneal_episodes": 200
        }
    },
    "dev_dqn": {
        "problem": "DevCartPole-v0",
        "Agent": "dqn.DQN",
        "Memory": "LinearMemoryWithForgetting",
        "Policy": "BoltzmannPolicy",
        "PreProcessor": "NoPreProcessor",
        "param": {
            "train_per_n_new_exp": 1,
            "learning_rate": 0.02,
            "gamma": 0.99,
            "hidden_layers_shape": [4],
            "hidden_layers_activation": "sigmoid",
            "exploration_anneal_episodes": 10
        },
        "param_range": {
            "learning_rate": [0.01, 0.1],
            "gamma": [0.95, 0.99],
            "exploration_anneal_episodes": [10, 20]
        }
    },
    "dqn": {
        "problem": "CartPole-v0",
        "Agent": "dqn.DQN",
        "Memory": "LinearMemoryWithForgetting",
        "Policy": "BoltzmannPolicy",
        "PreProcessor": "NoPreProcessor",
        "param": {
            "train_per_n_new_exp": 1,
            "learning_rate": 0.02,
            "gamma": 0.99,
            "hidden_layers_shape": [4],
            "hidden_layers_activation": "sigmoid",
            "exploration_anneal_episodes": 10
        },
        "param_range": {
            "learning_rate": [0.01, 0.1],
            "gamma": [0.95, 0.99],
            "exploration_anneal_episodes": [10, 20]
        }
    },
    "double_dqn": {
        "problem": "CartPole-v0",
        "Agent": "double_dqn.DoubleDQN",
        "Memory": "LinearMemory",
        "Policy": "EpsilonGreedyPolicy",
        "PreProcessor": "NoPreProcessor",
        "param": {
            "train_per_n_new_exp": 1,
            "learning_rate": 0.01,
            "batch_size": 32,
            "gamma": 0.99,
            "hidden_layers_shape": [4],
            "hidden_layers_activation": "sigmoid",
            "exploration_anneal_episodes": 180
        }
    },
    "mountain_dqn": {
        "problem": "MountainCar-v0",
        "Agent": "dqn.DQN",
        "Memory": "LinearMemoryWithForgetting",
        "Policy": "EpsilonGreedyPolicy",
        "PreProcessor": "NoPreProcessor",
        "param": {
            "train_per_n_new_exp": 4,
            "learning_rate": 0.001,
            "batch_size": 32,
            "gamma": 0.98,
            "hidden_layers_shape": [200, 100],
            "hidden_layers_activation": "relu",
            "exploration_anneal_episodes": 100
        },
        "param_range": {
            "learning_rate": [0.001, 0.01],
            "hidden_layers_shape": [
                [200, 100],
                [200, 100, 50]
            ]
        }
    },
    "mountain_double_dqn": {
        "problem": "MountainCar-v0",
        "Agent": "double_dqn.DoubleDQN",
        "Memory": "LinearMemory",
        "Policy": "EpsilonGreedyPolicy",
        "PreProcessor": "NoPreProcessor",
        "param": {
            "train_per_n_new_exp": 1,
            "learning_rate": 0.01,
            "batch_size": 128,
            "gamma": 0.99,
            "hidden_layers_shape": [8, 8],
            "hidden_layers_activation": "sigmoid",
            "exploration_anneal_episodes": 300
        }
    },
    "lunar_dqn": {
        "problem": "LunarLander-v2",
        "Agent": "dqn.DQN",
        "Memory": "HighLowMemoryWithForgetting",
        "Policy": "EpsilonGreedyPolicy",
        "PreProcessor": "StackStates",
        "param": {
            "train_per_n_new_exp": 5,
            "learning_rate": 0.001,
            "batch_size": 32,
            "gamma": 0.99,
            "hidden_layers_shape": [300, 150, 75],
            "hidden_layers_activation": "relu",
            "output_layer_activation": "linear",
            "exploration_anneal_episodes": 100,
            "epi_change_learning_rate": 200
        },
        "param_range": {
            "learning_rate": [0.005, 0.001, 0.0005, 0.0001],
            "epi_change_learning_rate": [75, 150, 200, 250],
            "hidden_layers_shape": [
                [200, 100],
                [300, 150],
                [300, 200],
                [300, 150, 75],
                [400, 200],
                [400, 200, 100],
                [400, 300]
            ]
        }
    },
    "lunar_double_dqn": {
        "problem": "LunarLander-v2",
        "Agent": "double_dqn.DoubleDQN",
        "Memory": "LinearMemory",
        "Policy": "EpsilonGreedyPolicy",
        "PreProcessor": "NoPreProcessor",
        "param": {
            "train_per_n_new_exp": 1,
            "learning_rate": 0.01,
            "batch_size": 64,
            "gamma": 0.99,
            "hidden_layers_shape": [200, 100],
            "hidden_layers_activation": "relu",
            "exploration_anneal_episodes": 500
        }
    },
    "air_raid_dqn": {
        "problem": "AirRaid-v0",
        "Agent": "atari_conv_dqn.ConvDQN",
        "Memory": "LongLinearMemoryWithForgetting",
        "Policy": "EpsilonGreedyPolicy",
        "PreProcessor": "Atari",
        "param": {
            "train_per_n_new_exp": 4,
            "learning_rate": 0.001,
            "batch_size": 32,
            "gamma": 0.99,
            "hidden_layers_shape": [
                [16, 8, 8, [4, 4]],
                [32, 4, 4, [2, 2]]
            ],
            "hidden_layers_activation": "relu",
            "exploration_anneal_episodes": 1000000,
            "epi_change_learning_rate": 1000000
        },
        "param_range": {
            "learning_rate": [0.001, 0.01],
            "hidden_layers_shape": [
                [200, 100],
                [300, 200],
                [200, 100, 50]
            ]
        }
    },
    "breakout_dqn": {
        "problem": "Breakout-v0",
        "Agent": "atari_conv_dqn.ConvDQN",
        "Memory": "LongLinearMemoryWithForgetting",
        "Policy": "EpsilonGreedyPolicy",
        "PreProcessor": "Atari",
        "param": {
            "train_per_n_new_exp": 4,
            "learning_rate": 0.001,
            "batch_size": 32,
            "gamma": 0.99,
            "hidden_layers_shape": [
                [16, 8, 8, [4, 4]],
                [32, 4, 4, [2, 2]]
            ],
            "hidden_layers_activation": "relu",
            "exploration_anneal_episodes": 5000,
            "epi_change_learning_rate": 5000
        },
        "param_range": {
            "learning_rate": [0.001, 0.01],
            "hidden_layers_shape": [
                [
                    [16, 8, 8, [4, 4]],
                    [32, 4, 4, [2, 2]]
                ]
            ]
        }
    }
}
