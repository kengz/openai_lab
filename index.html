<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>OpenAI Lab Doc</title>

    <style>
      .highlight table td { padding: 5px; }
.highlight table pre { margin: 0; }
.highlight {
  color: #faf6e4;
  background-color: #122b3b;
}
.highlight .gl {
  color: #dee5e7;
  background-color: #4e5d62;
}
.highlight .c, .highlight .cd, .highlight .cm, .highlight .c1, .highlight .cs {
  color: #6c8b9f;
  font-style: italic;
}
.highlight .cp {
  color: #b2fd6d;
  font-weight: bold;
  font-style: italic;
}
.highlight .err {
  color: #fefeec;
  background-color: #cc0000;
}
.highlight .gr {
  color: #fefeec;
  background-color: #cc0000;
}
.highlight .k, .highlight .kd, .highlight .kv {
  color: #f6dd62;
  font-weight: bold;
}
.highlight .o, .highlight .ow {
  color: #4df4ff;
}
.highlight .p, .highlight .pi {
  color: #4df4ff;
}
.highlight .gd {
  color: #cc0000;
}
.highlight .gi {
  color: #b2fd6d;
}
.highlight .ge {
  font-style: italic;
}
.highlight .gs {
  font-weight: bold;
}
.highlight .gt {
  color: #dee5e7;
  background-color: #4e5d62;
}
.highlight .kc {
  color: #f696db;
  font-weight: bold;
}
.highlight .kn {
  color: #ffb000;
  font-weight: bold;
}
.highlight .kp {
  color: #ffb000;
  font-weight: bold;
}
.highlight .kr {
  color: #ffb000;
  font-weight: bold;
}
.highlight .gh {
  color: #ffb000;
  font-weight: bold;
}
.highlight .gu {
  color: #ffb000;
  font-weight: bold;
}
.highlight .kt {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .no {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .nc {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .nd {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .nn {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .bp {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .ne {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .nl {
  color: #ffb000;
  font-weight: bold;
}
.highlight .nt {
  color: #ffb000;
  font-weight: bold;
}
.highlight .m, .highlight .mf, .highlight .mh, .highlight .mi, .highlight .il, .highlight .mo, .highlight .mb, .highlight .mx {
  color: #f696db;
  font-weight: bold;
}
.highlight .ld {
  color: #f696db;
  font-weight: bold;
}
.highlight .ss {
  color: #f696db;
  font-weight: bold;
}
.highlight .s, .highlight .sb, .highlight .sd, .highlight .s2, .highlight .sh, .highlight .sx, .highlight .sr, .highlight .s1 {
  color: #fff0a6;
  font-weight: bold;
}
.highlight .se {
  color: #4df4ff;
  font-weight: bold;
}
.highlight .sc {
  color: #4df4ff;
  font-weight: bold;
}
.highlight .si {
  color: #4df4ff;
  font-weight: bold;
}
.highlight .nb {
  font-weight: bold;
}
.highlight .ni {
  color: #999999;
  font-weight: bold;
}
.highlight .w {
  color: #BBBBBB;
}
.highlight .nf {
  color: #a8e1fe;
}
.highlight .py {
  color: #a8e1fe;
}
.highlight .na {
  color: #a8e1fe;
}
.highlight .nv, .highlight .vc, .highlight .vg, .highlight .vi {
  color: #a8e1fe;
  font-weight: bold;
}
    </style>
    <link href="stylesheets/screen.css" rel="stylesheet" media="screen" />
    <link href="stylesheets/print.css" rel="stylesheet" media="print" />
      <script src="javascripts/all.js"></script>
  </head>

  <body class="index" data-languages="[]">
    <a href="#" id="nav-button">
      <span>
        NAV
        <img src="images/navbar.png" alt="Navbar" />
      </span>
    </a>
    <div class="tocify-wrapper">
      <img src="images/logo.png" alt="Logo" />
        <div class="search">
          <input type="text" class="search" id="input-search" placeholder="Search">
        </div>
        <ul class="search-results"></ul>
      <div id="toc">
      </div>
        <ul class="toc-footer">
            <li><a href='https://github.com/kengz/openai_lab'>OpenAI Lab Github</a></li>
            <li><a href='https://github.com/openai/gym'>OpenAI Gym Github</a></li>
            <li><a href='https://github.com/fchollet/keras'>Keras Github</a></li>
            <li><a href='https://youtu.be/qBhLoeijgtA'>RL Tutorial video part 1/2</a></li>
            <li><a href='https://youtu.be/wNSlZJGdodE'>RL Tutorial video part 2/2</a></li>
        </ul>
    </div>
    <div class="page-wrapper">
      <div class="dark-box"></div>
      <div class="content">
        <h1 id="openai-lab">OpenAI Lab </br> <a href="https://circleci.com/gh/kengz/openai_lab"><img src="https://circleci.com/gh/kengz/openai_lab.svg?style=shield" alt="CircleCI" /></a> <a href="https://www.codacy.com/app/kengzwl/openai_lab?utm_source=github.com&amp;amp;utm_medium=referral&amp;amp;utm_content=kengz/openai_lab&amp;amp;utm_campaign=Badge_Grade"><img src="https://api.codacy.com/project/badge/Grade/a0e6bbbb6c4845ccaab2db9aecfecbb0" alt="Codacy Badge" /></a> <a href="https://www.codacy.com/app/kengzwl/openai_lab?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=kengz/openai_lab&amp;utm_campaign=Badge_Coverage"><img src="https://api.codacy.com/project/badge/Coverage/9e55f845b10b4b51b213620bfb98e4b3" alt="Codacy Badge" /></a> <a href="https://github.com/kengz/openai_lab"><img src="https://img.shields.io/github/forks/kengz/openai_lab.svg?style=social&amp;label=Fork" alt="GitHub forks" /></a> <a href="https://github.com/kengz/openai_lab"><img src="https://img.shields.io/github/stars/kengz/openai_lab.svg?style=social&amp;label=Star" alt="GitHub stars" /></a></h1>

<p><strong>(DOC UNDER CONSTRUCTION)</strong></p>

<p><em>An experimentation system for Reinforcement Learning using OpenAI and Keras.</em></p>

<p>The <em>OpenAI Lab</em> is created to do Reinforcement Learning (RL) like science - <em>theorize, experiment</em>. It provides an easy to use interface to <a href="https://gym.openai.com/">OpenAI Gym</a> and <a href="https://keras.io/">Keras</a>, combined with an automated experimental and analytics framework.</p>

<p>While these are powerful tools, they take a lot to get running. Of many implementations we saw which solve OpenAI gym environments, many had to rewrite the same basic components instead of just the new components being researched.</p>

<p>To address this, the Lab does three things.</p>

<ol>
<li>Handles the basic RL environment and algorithm setups.</li>
<li>Provides a standard, extensible platform with reusable components for developing deep reinforcement learning algorithms.</li>
<li>Provides a rigorous experimentation system with logs, plots and analytics for testing new RL algorithms. Experimental settings are logged in a standardized format so that solutions can be reproduced by anyone using the Lab.</li>
</ol>

<p>With OpenAI Lab, we could focus on researching the essential elements of reinforcement learning such as the algorithm, policy, memory (experience replay), and parameter tuning to solve the OpenAI environments. We could also test our hypotheses more reliably.</p>

<p>See the <a href="#solutions">Best Solutions</a> to some OpenAI environments that OpenAI Lab users have produced.</p>

<h3 id="run-the-lab">Run the Lab</h3>

<p>Next, see <a href="#installation">Installation</a> and <a href="#usage">Usage</a>.</p>

<div style="max-width: 100%"><img alt="Timelapse of OpenAI Lab" src="./images/lab_demo_dqn.gif" /></div>

<p><em>Timelapse of OpenAI Lab, solving CartPole-v0.</em></p>

          <h1 id="installation"><a name="installation"></a>Installation</h1>

<p>1. Clone repo and run the setup script:</p>
<pre class="highlight shell"><code>git clone https://github.com/kengz/openai_lab.git
<span class="nb">cd </span>openai_lab
./bin/setup
</code></pre>
<p><code class="prettyprint">bin/setup</code> installs all the dependencies the same way as our servers and <a href="https://circleci.com/gh/kengz/openai_lab">CircleCI builds</a>; inspect or change it as needed. Also make sure your dependencies are the most updated - check the <a href="#dependencies">major required versions here</a>.</p>

<aside class="notice">
If you use OpenAI Lab for serious experimentations, fork this repo then clone your fork, so you can commit code and contribute to the Lab.
</aside>

<p>2. Keras needs a backend in your home directory; setup <code class="prettyprint">~/.keras/keras.json</code> using the example file in <code class="prettyprint">config/keras.json</code>.</p>
<pre class="highlight json"><code><span class="p">{</span><span class="w">
  </span><span class="s2">"epsilon"</span><span class="p">:</span><span class="w"> </span><span class="mi">1e-07</span><span class="p">,</span><span class="w">
  </span><span class="s2">"image_dim_ordering"</span><span class="p">:</span><span class="w"> </span><span class="s2">"tf"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"floatx"</span><span class="p">:</span><span class="w"> </span><span class="s2">"float32"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"backend"</span><span class="p">:</span><span class="w"> </span><span class="s2">"tensorflow"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
<aside class="notice">
We recommend Tensorflow for experimentation with multi-GPU for stability. By default <code>bin/setup</code> will install <code>tensorflow</code> for MacOS and <code>tensorflow-gpu</code> for Linux.
If you wish, use Theano once your lab produces a final model for a single retraining, since it&rsquo;s faster.
</aside>

<p>3. <code class="prettyprint">bin/setup</code> also creates the needed config files needed for lab <a href="#usage">usage</a>. See sections below for more info.</p>

<ul>
<li><code class="prettyprint">config/default.json</code> for local development, used when <code class="prettyprint">grunt</code> is ran without a production flag.</li>
<li><code class="prettyprint">config/production.json</code> for production lab run when <code class="prettyprint">grunt -prod</code> is ran with the production flag <code class="prettyprint">-prod</code>.</li>
</ul>
<pre class="highlight json"><code><span class="p">{</span><span class="w">
  </span><span class="s2">"data_sync_destination"</span><span class="p">:</span><span class="w"> </span><span class="s2">"~/Dropbox/openai_lab/data"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"NOTI_SLACK_DEST"</span><span class="p">:</span><span class="w"> </span><span class="s2">"#rl-monitor"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"NOTI_SLACK_TOK"</span><span class="p">:</span><span class="w"> </span><span class="s2">"GET_SLACK_BOT_TOKEN_FROM_https://my.slack.com/services/new/bot"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"experiments"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="s2">"dev_dqn"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"dqn"</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
<h2 id="setup-data-auto-sync">Setup Data Auto-sync</h2>

<p>We find it extremely useful to have data file-sync when running the lab on a remote server. This allows us to have a live view of the experiment graphs and data on our Dropbox app, on a computer or a smartphone.</p>

<p>For auto-syncing lab <code class="prettyprint">data/</code> we use <a href="http://gruntjs.com/">Grunt</a> file watcher for automatically copying data files to Dropbox. In your dropbox, set up a shared folder <code class="prettyprint">~/Dropbox/openai_lab/data</code> and sync to desktop.</p>

<aside class="notice">
Setup the config key <code>data_sync_destination</code> in <code>config/{default.json, production.json}</code>.
</aside>

<h2 id="setup-auto-notification">Setup Auto-notification</h2>

<p>Experiments take a while to run, and we find it useful also to be notified automatically on completion. We use <a href="https://github.com/variadico/noti">noti</a>, which is also installed with <code class="prettyprint">bin/setup</code>.</p>

<p>Set up a Slack, create a new channel <code class="prettyprint">#rl_monitor</code>, and get a <a href="https://my.slack.com/services/new/bot">Slack bot token</a>.</p>

<aside class="notice">
Setup the config keys <code>NOTI_SLACK_DEST</code>, <code>NOTI_SLACK_TOK</code> in <code>config/{default.json, production.json}</code>.
</aside>

<p><img alt="Notifications from the lab running on our remote server beast" src="./images/noti.png" />
<em>Notifications from the lab running on our remote server beast.</em></p>

<h2 id="setup-experiments">Setup Experiments</h2>

<p>There are many existing experiments specified in <code class="prettyprint">rl/spec/*_experiment_specs.json</code>, and you can add more. Pick the <code class="prettyprint">experiment_name</code>s (e.g. <code class="prettyprint">&quot;dqn&quot;, &quot;lunar_dqn&quot;</code>), specify in <code class="prettyprint">config/default.json</code> or <code class="prettyprint">config/production.json</code>. Then check <a href="#usage">usage</a> to run the lab.</p>

<h2 id="dependencies"><a name="dependencies"></a>Dependencies</h2>

<p>There is more than a dozen of dependencies. For the full list, inspect <code class="prettyprint">bin/setup</code>. Here are some major ones and their minimal required versions. If Lab fails to run, check these first:</p>

<ul>
<li><code class="prettyprint">python3 &gt;= 3.4</code></li>
<li><code class="prettyprint">node &gt;= 7.0</code></li>
<li><code class="prettyprint">tensorflow &gt;= 1.0</code> or <code class="prettyprint">tensorflow-gpu &gt;= 1.0</code></li>
<li><code class="prettyprint">theano == 0.8.2</code></li>
<li><code class="prettyprint">keras &gt;= 1.2</code></li>
<li><code class="prettyprint">gym[all] &gt;= 0.7</code></li>
</ul>

<h2 id="hardware">Hardware</h2>

<p>For setting up your own hardware, especially with a GPU, googling will help more than we could. Also, setup is usually non-trivial since there&rsquo;re so many moving parts. Here&rsquo;s the recommended references:</p>

<ul>
<li><a href="https://pcpartpicker.com/list/xdbWBP">A ~$1000 PC build</a> (more expensive now ~$1200; buy your parts during Black Friday/sales.)</li>
<li><a href="https://www.tensorflow.org/install/install_linux">The official TensorFlow installation guide, with GPU setup info</a></li>
<li><a href="http://christopher5106.github.io/nvidia/2016/12/30/commands-nvidia-install-ubuntu-16-04.html">Getting CUDA 8 to Work With openAI Gym on AWS and Compiling Tensorflow for CUDA 8 Compatibility</a></li>
<li><a href="https://github.com/openai/gym/issues/366">Major OpenAI issue with SSH with xvfb failing with NVIDIA Driver due to opengl files</a></li>
<li><a href="http://askubuntu.com/questions/149206/how-to-install-nvidia-run">NVIDIA cannot install due to X server running</a></li>
<li><a href="http://askubuntu.com/questions/759641/cant-get-nvidia-drivers-working-with-16-04-logs-out-right-after-login">When login fails on Ubuntu after Nvidia installation</a></li>
</ul>

          <h1 id="usage"><a name="usage"></a>Usage</h1>

<p><em>To understand the Lab&rsquo;s <a href="#framework">Framework and Demo, skip to the next section.</a></em></p>

<p>The general flow for running a production lab is:</p>

<ol>
<li>Specify experiment specs in <code class="prettyprint">rl/spec/*_experiment_specs.json</code>, e.g. <code class="prettyprint">&quot;dqn&quot;, &quot;lunar_dqn&quot;</code></li>
<li>Specify the names of the experiments to run in <code class="prettyprint">config/production.json</code></li>
<li>Run the lab, e.g. <code class="prettyprint">grunt -prod -resume</code></li>
</ol>

<h2 id="commands">Commands</h2>

<p>We use <a href="http://gruntjs.com/">Grunt</a> to run the lab - set up experiments, pause/resume lab, run analyses, sync data, notify on completion. Internally <code class="prettyprint">grunt</code> runs the <code class="prettyprint">python</code> command (harder to use), logged to stdout as <code class="prettyprint">&gt;&gt; Composed command: python3 main.py ...</code></p>

<p>The useful grunt commands are:</p>
<pre class="highlight shell"><code><span class="c"># when developing experiments specified in default.json</span>
grunt

<span class="c"># run real lab experiments specified in production.json</span>
grunt -prod
<span class="c"># run lab over ssh on remote server</span>
grunt -prod -remote
<span class="c"># resume lab (previously incomplete experiments)</span>
grunt -prod -remote -resume

<span class="c"># plot analysis graphs only</span>
grunt analyze -prod

<span class="c"># clear data/ folder and cache files</span>
grunt clear
</code></pre>
<p>See below for the full <a href="#grunt-cmd">Grunt Command Reference</a> or the <a href="#python-cmd">Python Command Reference</a>.</p>

<p><strong>development</strong> mode:</p>

<ul>
<li>All grunt commands default to this mode</li>
<li>specify your dev experiment in <code class="prettyprint">config/default.json</code></li>
<li>use only when developing your new algorithms</li>
<li>the file-sync is in mock mode (emulated log without real file copying)</li>
<li>no auto-notification</li>
</ul>

<p><strong>production</strong> mode:</p>

<ul>
<li>append the flag <code class="prettyprint">-prod</code> to your <code class="prettyprint">grunt</code> command</li>
<li>specify your full experiments in <code class="prettyprint">config/production.json</code></li>
<li>use when running experiments for real</li>
<li>the file-sync is real</li>
<li>has auto-notification to Slack channel</li>
</ul>

<h2 id="run-remotely">Run Remotely</h2>

<p>If you&rsquo;re using a remote server, run the commands inside a <code class="prettyprint">screen</code>. That is, log in via ssh, start a screen, run, then detach screen.</p>
<pre class="highlight shell"><code><span class="c"># enter the screen with the name "lab"</span>
screen -S lab
<span class="c"># run real lab over ssh, in resume mode</span>
grunt -prod -remote -resume
<span class="c"># use Cmd+A+D to detach from screen, then Cmd+D to disconnect ssh</span>

<span class="c"># to resume screen next time</span>
screen -r lab
<span class="c"># use Cmd+D to terminate screen when lab ends</span>
</code></pre>
<p>Since a remote server is away, you should check the system status occasionally to ensure no overrunning processes (memory growth, large processes, overheating). Use <a href="https://github.com/nicolargo/glances"><code class="prettyprint">glances</code></a> (already installed in <code class="prettyprint">bin/setup</code>) to monitor your expensive machines.</p>

<aside class="notice">
To monitor your system (CPU, RAM, GPU), run <code>glances</code>
</aside>

<p><img alt="Glances to monitor your system" src="./images/glances.png" />
<em>Glances on remote server beast.</em></p>

<h2 id="resume-lab">Resume Lab</h2>

<p>Experiments take a long time to complete, and if your process gets terminated, resuming the lab is trivial with a <code class="prettyprint">-resume</code> flag: <code class="prettyprint">grunt -prod -remote -resume</code>. This will use the <code class="prettyprint">config/history.json</code>:</p>
<pre class="highlight json"><code><span class="p">{</span><span class="w">
  </span><span class="s2">"dqn"</span><span class="p">:</span><span class="w"> </span><span class="s2">"dqn-2017_03_19_004714"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
<p>The <code class="prettyprint">config/history.json</code> is created in the last run that maps <code class="prettyprint">experiment_name</code>s to <code class="prettyprint">experiment_id</code>s, and resume any incomplete experiments based on that <code class="prettyprint">experiment_id</code>. You can manually tweak the file to set the resume target of course.</p>

<h2 id="grunt-command-reference"><a name="grunt-cmd"></a>Grunt Command Reference</h2>

<p>By default the <code class="prettyprint">grunt</code> command (no task or flag) runs the lab in <code class="prettyprint">development</code> mode using <code class="prettyprint">config/default.json</code>.</p>

<p>The basic grunt command pattern is</p>
<pre class="highlight shell"><code>grunt &lt;task&gt; -&lt;flag&gt;

<span class="c"># again, the useful grunt commands are:</span>

<span class="c"># when developing experiments specified in default.json</span>
grunt

<span class="c"># run real lab experiments specified in production.json</span>
grunt -prod
<span class="c"># run lab over ssh on remote server</span>
grunt -prod -remote
<span class="c"># resume lab (previously incomplete experiments)</span>
grunt -prod -remote -resume

<span class="c"># plot analysis graphs only</span>
grunt analyze -prod

<span class="c"># clear data/ folder and cache files</span>
grunt clear
</code></pre>
<p>The <code class="prettyprint">&lt;task&gt;</code>s are:</p>

<ul>
<li><em>(default empty)</em>: run the lab</li>
<li><code class="prettyprint">analyze</code>: generate analysis data and graphs only, without running the lab. This can be used when you wish to see the analysis results midway during a long-running experiment. Run it on a separate terminal window as <code class="prettyprint">grunt analyze -prod</code></li>
<li><code class="prettyprint">clear</code>: clear the <code class="prettyprint">data/</code> folder and cache files. <strong>Be careful</strong> and make sure your data is already copied to the sync location</li>
</ul>

<p>The <code class="prettyprint">&lt;flag&gt;</code>s are:</p>

<ul>
<li><code class="prettyprint">-prod</code>: production mode, use <code class="prettyprint">config/production.json</code></li>
<li><code class="prettyprint">-resume</code>: resume incomplete experiments from <code class="prettyprint">config/history.json</code></li>
<li><code class="prettyprint">-remote</code>: when running over SSH, supplies this to use a fake display</li>
<li><code class="prettyprint">-best</code>: run the finalized experiments with gym rendering and live plotting; without param selection. This uses the default <code class="prettyprint">param</code> in <code class="prettyprint">experiment_specs.json</code> that shall be updated to the best found.</li>
<li><code class="prettyprint">-quiet</code>: mute all python logging in grunt. This is for lab-level development only.</li>
</ul>

<h2 id="python-command-reference"><a name="python-cmd"></a>Python Command Reference</h2>

<p>The Python command is invoked inside <code class="prettyprint">Gruntfile.js</code> under the <code class="prettyprint">composeCommand</code> function. Change it if you need to.</p>

<p>The basic python command pattern is:</p>
<pre class="highlight shell"><code>python3 main.py -&lt;flag&gt;

<span class="c"># most common example, with piping of terminal log</span>
python3 main.py -bp -t 5 -e dqn | tee -a ./data/terminal.log;
</code></pre>
<p>The python command <flag>s are:</p>

<ul>
<li><code class="prettyprint">-a</code>: Run <code class="prettyprint">analyze_experiment()</code> only to plot <code class="prettyprint">experiment_data</code>. Default: <code class="prettyprint">False</code></li>
<li><code class="prettyprint">-b</code>: blind mode, do not render graphics. Default: <code class="prettyprint">False</code></li>
<li><code class="prettyprint">-d</code>: log debug info. Default: <code class="prettyprint">False</code></li>
<li><code class="prettyprint">-e &lt;experiment&gt;</code>: specify which inside the <code class="prettyprint">rl/spec/*_experiment_spec.json</code> to run. Default: <code class="prettyprint">-e dev_dqn</code>. Can be a <code class="prettyprint">experiment_name, experiment_id</code>.</li>
<li><code class="prettyprint">-p</code>: run param selection. Default: <code class="prettyprint">False</code></li>
<li><code class="prettyprint">-q</code>: quiet mode, log warning only. Default: <code class="prettyprint">False</code></li>
<li><code class="prettyprint">-t &lt;times&gt;</code>: the number of sessions to run per trial. Default: <code class="prettyprint">1</code></li>
<li><code class="prettyprint">-x &lt;max_episodes&gt;</code>: Manually specifiy max number of episodes per trial. Default: <code class="prettyprint">-1</code> and program defaults to value in <code class="prettyprint">rl/spec/problems.json</code></li>
</ul>

          <h1 id="experiments"><a name="experiments"></a>Experiments</h1>

<p>The experimental framework design and terminology should be familiar, since it&rsquo;s borrowed from experimental science. The Lab runs <strong>experiments</strong> and produces data for <a href="#analysis">analysis</a>.</p>

<h2 id="definition">Definition</h2>

<p>An <strong>experiment</strong> runs separate <strong>trials</strong> by varying parameters. Each <strong>trial</strong> runs multiple <strong>sessions</strong> for averaging the results.</p>

<p>An experiment consists of:</p>

<ul>
<li>an <strong>environment</strong> (problem) from <a href="https://gym.openai.com/envs">OpenAI Gym</a></li>
<li>an <strong>agent</strong> to solve the environment.</li>
</ul>

<aside class="notice">
An experiment runs the variations of agent by changing its parameters (experiment variables) while holding others constants (control), and measure the fitness_score (outcome) to solve the environment.
</aside>

<h2 id="specification">Specification</h2>

<p>An experiment is specified by an <code class="prettyprint">experiment_spec</code> in <code class="prettyprint">rl/spec/*_experiment_specs.json</code>.</p>
<pre class="highlight json"><code><span class="p">{</span><span class="w">
  </span><span class="s2">"dqn"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="s2">"problem"</span><span class="p">:</span><span class="w"> </span><span class="s2">"CartPole-v0"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Agent"</span><span class="p">:</span><span class="w"> </span><span class="s2">"DQN"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"HyperOptimizer"</span><span class="p">:</span><span class="w"> </span><span class="s2">"GridSearch"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Memory"</span><span class="p">:</span><span class="w"> </span><span class="s2">"LinearMemoryWithForgetting"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Optimizer"</span><span class="p">:</span><span class="w"> </span><span class="s2">"AdamOptimizer"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Policy"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BoltzmannPolicy"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"PreProcessor"</span><span class="p">:</span><span class="w"> </span><span class="s2">"NoPreProcessor"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"param"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="s2">"lr"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.02</span><span class="p">,</span><span class="w">
      </span><span class="s2">"gamma"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.99</span><span class="p">,</span><span class="w">
      </span><span class="s2">"hidden_layers"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">64</span><span class="p">],</span><span class="w">
      </span><span class="s2">"hidden_layers_activation"</span><span class="p">:</span><span class="w"> </span><span class="s2">"sigmoid"</span><span class="p">,</span><span class="w">
      </span><span class="s2">"exploration_anneal_episodes"</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="s2">"param_range"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="s2">"lr"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.001</span><span class="p">,</span><span class="w"> </span><span class="mf">0.005</span><span class="p">,</span><span class="w"> </span><span class="mf">0.01</span><span class="p">,</span><span class="w"> </span><span class="mf">0.02</span><span class="p">],</span><span class="w">
      </span><span class="s2">"gamma"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.95</span><span class="p">,</span><span class="w"> </span><span class="mf">0.97</span><span class="p">,</span><span class="w"> </span><span class="mf">0.99</span><span class="p">,</span><span class="w"> </span><span class="mf">0.999</span><span class="p">],</span><span class="w">
      </span><span class="s2">"hidden_layers"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">[</span><span class="mi">16</span><span class="p">],</span><span class="w">
        </span><span class="p">[</span><span class="mi">32</span><span class="p">],</span><span class="w">
        </span><span class="p">[</span><span class="mi">64</span><span class="p">],</span><span class="w">
        </span><span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">],</span><span class="w">
        </span><span class="p">[</span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">16</span><span class="p">]</span><span class="w">
      </span><span class="p">]</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
<p>It consists of:</p>

<ul>
<li><code class="prettyprint">experiment_name</code>: the key of the JSON. e.g. <code class="prettyprint">dqn</code></li>
<li><code class="prettyprint">problem</code>: name of the environment. e.g. <code class="prettyprint">CartPole-v0</code></li>
<li><strong>agent</strong>: and its components in <code class="prettyprint">rl/</code>, specified by the class name

<ul>
<li><code class="prettyprint">Agent</code>: the main agent class, typically with the algorithm like <code class="prettyprint">DQN, DDPG</code></li>
<li><code class="prettyprint">HyperOptimizer</code>: hyperparameter optimization algorithms used to vary the agent parameters and run trials with them</li>
<li><code class="prettyprint">Memory</code>: the memory module of the agent, to specify how agent control or access memory</li>
<li><code class="prettyprint">Optimizer</code>: the neural network optimizer of Agent</li>
<li><code class="prettyprint">Policy</code>: the externalized policy of Agent</li>
<li><code class="prettyprint">PreProcessor</code>: for the environment states. Useful for Atari with images.</li>
</ul></li>
<li><code class="prettyprint">param</code>: the default parameter values used (control variables)</li>
<li><code class="prettyprint">param_range</code>: the hyperparameter space ranges to search through by <code class="prettyprint">HyperOptimimzer</code> (experiment variables).</li>
</ul>

<h2 id="breakdown">Breakdown</h2>

<p>How <code class="prettyprint">experiments &gt; trials &gt; sessions</code> are organized and ran.</p>

<p>When the Lab runs an <strong>experiment</strong> with <code class="prettyprint">experiment_name</code> (e.g. <code class="prettyprint">dqn</code>):</p>

<ul>
<li>it creates a timestamped <code class="prettyprint">experiment_id</code> (<code class="prettyprint">dqn-2017_03_19_004714</code>)</li>
<li>the <strong>experiment</strong> runs multiple trials over the hyperparameter space

<ul>
<li>the trials are ordered for resumability (in case machine dies)</li>
<li>each trial has <code class="prettyprint">trial_id</code> (<code class="prettyprint">dqn-2017_03_19_004714_t0</code>), tied to a unique set of param values</li>
<li>a <strong>trial</strong> runs multiple sessions

<ul>
<li>each <strong>session</strong> has <code class="prettyprint">session_id</code> (<code class="prettyprint">dqn-2017_03_19_004714_t0_s0</code>)</li>
<li>a session runs the environment-agent, produces graphs and <code class="prettyprint">session_data</code> i.e. <code class="prettyprint">sys_vars</code></li>
<li>the session saves its graph to <code class="prettyprint">&lt;session_id&gt;.png</code></li>
<li>the session returns <code class="prettyprint">sys_vars</code> to its trial</li>
</ul></li>
<li>the trial gathers all the <code class="prettyprint">sys_vars</code>, run some averaging analytics, then compose all that into <code class="prettyprint">trial_data</code></li>
<li>the trial returns the <code class="prettyprint">trial_data</code> and saves it to <code class="prettyprint">&lt;trial_id&gt;.json</code></li>
</ul></li>
<li>the experiment composes all <code class="prettyprint">trial_data</code> into a <code class="prettyprint">experiment_data</code></li>
<li>it runs analytics to produce graphs <code class="prettyprint">&lt;experiment_id&gt;_analysis.png, &lt;experiment_id&gt;_correlation.png</code></li>
<li>it compute the <code class="prettyprint">fitness_score</code> for each trial, rank them by best-first, then save the data grid to <code class="prettyprint">&lt;experiment_id&gt;_analysis_data.csv</code></li>
<li>experiment ends</li>
</ul>

<h2 id="lab-demo">Lab Demo</h2>

<p>Given the framework explained above, here&rsquo;s a quick demo. Suppose we aim to solve the CartPole-v0 problem with the plain DQN agent.  Suppose again for this experiment, we implement a new agent component, namely a <code class="prettyprint">Boltzmann</code> policy, and try to find the best parameter sets for this new agent.</p>

<h3 id="specify-experiment">Specify Experiment</h3>

<p>The example below is fully specified in <code class="prettyprint">rl/spec/classic_experiment_specs.json</code> under <code class="prettyprint">dqn</code>:</p>
<pre class="highlight json"><code><span class="p">{</span><span class="w">
  </span><span class="s2">"dqn"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="s2">"problem"</span><span class="p">:</span><span class="w"> </span><span class="s2">"CartPole-v0"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Agent"</span><span class="p">:</span><span class="w"> </span><span class="s2">"DQN"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"HyperOptimizer"</span><span class="p">:</span><span class="w"> </span><span class="s2">"GridSearch"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Memory"</span><span class="p">:</span><span class="w"> </span><span class="s2">"LinearMemoryWithForgetting"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Optimizer"</span><span class="p">:</span><span class="w"> </span><span class="s2">"AdamOptimizer"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Policy"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BoltzmannPolicy"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"PreProcessor"</span><span class="p">:</span><span class="w"> </span><span class="s2">"NoPreProcessor"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"param"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="s2">"lr"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.02</span><span class="p">,</span><span class="w">
      </span><span class="s2">"gamma"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.99</span><span class="p">,</span><span class="w">
      </span><span class="s2">"hidden_layers"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">64</span><span class="p">],</span><span class="w">
      </span><span class="s2">"hidden_layers_activation"</span><span class="p">:</span><span class="w"> </span><span class="s2">"sigmoid"</span><span class="p">,</span><span class="w">
      </span><span class="s2">"exploration_anneal_episodes"</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="s2">"param_range"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="s2">"lr"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.001</span><span class="p">,</span><span class="w"> </span><span class="mf">0.005</span><span class="p">,</span><span class="w"> </span><span class="mf">0.01</span><span class="p">,</span><span class="w"> </span><span class="mf">0.02</span><span class="p">],</span><span class="w">
      </span><span class="s2">"gamma"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.95</span><span class="p">,</span><span class="w"> </span><span class="mf">0.97</span><span class="p">,</span><span class="w"> </span><span class="mf">0.99</span><span class="p">,</span><span class="w"> </span><span class="mf">0.999</span><span class="p">],</span><span class="w">
      </span><span class="s2">"hidden_layers"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">[</span><span class="mi">16</span><span class="p">],</span><span class="w">
        </span><span class="p">[</span><span class="mi">32</span><span class="p">],</span><span class="w">
        </span><span class="p">[</span><span class="mi">64</span><span class="p">],</span><span class="w">
        </span><span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">],</span><span class="w">
        </span><span class="p">[</span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="mi">16</span><span class="p">]</span><span class="w">
      </span><span class="p">]</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
<p>Specifically of interests, we have specified the variables:</p>

<ul>
<li><em>experiment_name</em>: <code class="prettyprint">dqn</code></li>
<li><em>problem</em>: <a href="https://gym.openai.com/envs/CartPole-v0">CartPole-v0</a></li>
<li><em>variable agent component</em>: <code class="prettyprint">Boltzmann</code> policy</li>
<li><em>control agent variables</em>:

<ul>
<li><code class="prettyprint">DQN</code> agent</li>
<li><code class="prettyprint">LinearMemoryWithForgetting</code></li>
<li><code class="prettyprint">AdamOptimizer</code></li>
<li><code class="prettyprint">NoPreProcessor</code></li>
</ul></li>
<li><em>hyperparameter space</em>: the <code class="prettyprint">&quot;param_range&quot;</code> JSON</li>
<li><em>hyperparameter optimizer</em>: <code class="prettyprint">GridSearch</code></li>
</ul>

<p>Given <code class="prettyprint">GridSearch HyperOptimizer</code>, this <strong>experiment</strong> will try all the discrete combinations of the <code class="prettyprint">param_range</code>, which makes for <code class="prettyprint">4x4x5=80</code> trials. Each <strong>trial</strong> will run a max of 5 <strong>sessions</strong> (terminate on 2 if fail to solve). Overall, this experiments will run at most <code class="prettyprint">80 x 5 = 400</code> sessions, then produce <code class="prettyprint">experiment_data</code> and the analytics.</p>

<h3 id="lab-workflow">Lab Workflow</h3>

<p>The example workflow to setup this experiment is as follow:</p>

<ol>
<li>Add the new theorized component <code class="prettyprint">Boltzmann</code> in <code class="prettyprint">rl/policy/boltzmann.py</code></li>
<li>Specify <code class="prettyprint">dqn</code> experiment spec in <code class="prettyprint">rl/spec/classic_experiment_spec.json</code> to include this new variable, reuse the other existing RL components, and specify the param range.</li>
<li>Add this experiment to the lab queue in <code class="prettyprint">config/production.json</code></li>
<li>Run experiment with <code class="prettyprint">grunt -prod</code></li>
<li>Analyze the graphs and data</li>
</ol>

<p>Now that you can produce the experiment data and graphs, see how to <a href="#analysis">analyze them</a>.</p>

          <h1 id="analysis"><a name="analysis"></a>Analysis</h1>

<p>How to analyze your lab results, and contribute to <a href="#solutions">Best Solutions</a></p>

<p>Follow the running process chain of data n graphs produced.</p>

<p>submit these when u solve (link to submission)</p>

<p>fitness ratio explanation</p>

<h2 id="lab-results">Lab Results</h2>

<div style="max-width: 100%"><img alt="The dqn experiment analytics" src="./images/dqn.png" />
<br><br></div>

<p><img alt="The dqn experiment analytics correlation" src="./images/dqn_correlation.png" /></p>

<p><em>The dqn experiment analytics generated by the Lab. This is a pairplot, where we isolate each variable, flatten the others, plot each trial as a point. The darker the color the higher ratio of the repeated sessions the trial solves.</em></p>

<table><thead>
<tr>
<th style="text-align: left">fitness_score</th>
<th style="text-align: left">mean_rewards_per_epi_stats_mean</th>
<th style="text-align: left">mean_rewards_stats_mean</th>
<th style="text-align: left">epi_stats_mean</th>
<th style="text-align: left">solved_ratio_of_sessions</th>
<th style="text-align: left">num_of_sessions</th>
<th style="text-align: left">max_total_rewards_stats_mean</th>
<th style="text-align: left">t_stats_mean</th>
<th style="text-align: left">trial_id</th>
<th style="text-align: left">variable_gamma</th>
<th style="text-align: left">variable_hidden_layers</th>
<th style="text-align: left">variable_lr</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left">5.305994917071314</td>
<td style="text-align: left">1.3264987292678285</td>
<td style="text-align: left">195.404</td>
<td style="text-align: left">154.2</td>
<td style="text-align: left">1.0</td>
<td style="text-align: left">5</td>
<td style="text-align: left">200.0</td>
<td style="text-align: left">199.0</td>
<td style="text-align: left">dqn-2017_03_19_004714_t79</td>
<td style="text-align: left">0.999</td>
<td style="text-align: left">[64]</td>
<td style="text-align: left">0.02</td>
</tr>
<tr>
<td style="text-align: left">5.105207228739003</td>
<td style="text-align: left">1.2763018071847507</td>
<td style="text-align: left">195.13600000000002</td>
<td style="text-align: left">160.6</td>
<td style="text-align: left">1.0</td>
<td style="text-align: left">5</td>
<td style="text-align: left">200.0</td>
<td style="text-align: left">199.0</td>
<td style="text-align: left">dqn-2017_03_19_004714_t50</td>
<td style="text-align: left">0.99</td>
<td style="text-align: left">[32]</td>
<td style="text-align: left">0.01</td>
</tr>
<tr>
<td style="text-align: left">4.9561426920909355</td>
<td style="text-align: left">1.2390356730227339</td>
<td style="text-align: left">195.26000000000002</td>
<td style="text-align: left">168.6</td>
<td style="text-align: left">1.0</td>
<td style="text-align: left">5</td>
<td style="text-align: left">200.0</td>
<td style="text-align: left">199.0</td>
<td style="text-align: left">dqn-2017_03_19_004714_t78</td>
<td style="text-align: left">0.999</td>
<td style="text-align: left">[64]</td>
<td style="text-align: left">0.01</td>
</tr>
<tr>
<td style="text-align: left">4.76714626254895</td>
<td style="text-align: left">1.1917865656372375</td>
<td style="text-align: left">195.106</td>
<td style="text-align: left">172.4</td>
<td style="text-align: left">1.0</td>
<td style="text-align: left">5</td>
<td style="text-align: left">200.0</td>
<td style="text-align: left">199.0</td>
<td style="text-align: left">dqn-2017_03_19_004714_t71</td>
<td style="text-align: left">0.999</td>
<td style="text-align: left">[32]</td>
<td style="text-align: left">0.02</td>
</tr>
<tr>
<td style="text-align: left">4.717243567762263</td>
<td style="text-align: left">1.1793108919405657</td>
<td style="text-align: left">195.56400000000002</td>
<td style="text-align: left">167.2</td>
<td style="text-align: left">1.0</td>
<td style="text-align: left">5</td>
<td style="text-align: left">200.0</td>
<td style="text-align: left">199.0</td>
<td style="text-align: left">dqn-2017_03_19_004714_t28</td>
<td style="text-align: left">0.97</td>
<td style="text-align: left">[32]</td>
<td style="text-align: left">0.001</td>
</tr>
</tbody></table>

<p><em>Analysis data table, top 5 trials.</em></p>

<p>On completion, from the analytics, we conclude that the experiment is a success, and the best agent that solves the problem has the parameters:</p>

<ul>
<li><em>lr</em>: 0.02</li>
<li><em>gamma</em>: 0.999</li>
<li><em>hidden_layers_shape</em>: [64]</li>
</ul>

<h2 id="variables">Variables</h2>

<p>the aggregate &hellip; see analytics module</p>

<h2 id="data">Data</h2>

<p>jsons and sorted CSV</p>

<h2 id="graphs">Graphs</h2>

<p>Main and correlation, how to read</p>

          <h2 id="metrics"><a name="metrics"></a>Metrics</h2>

<p>(pending long writeup)</p>

<p>OpenAI Lab exists to address 2 major problems in RL, and WildML&rsquo;s Denny sums them up best in his post <a href="http://blog.dennybritz.com/2017/01/17/engineering-is-the-bottleneck-in-deep-learning-research/">Engineering Is The Bottleneck In (Deep Learning) Research</a>. They are:</p>

<p><strong>1. the difficulty of building upon otherâ€™s work</strong></p>

<p>As the Lab grows, we hope that engineers and researchers can experiment with an idea fast by building on top of our existing components.</p>

<p><strong>2. the lack of rigor in comparisons</strong></p>

<p>Multiple experiments running in the Lab will produce the same analytics and the evaluation metrics. This will allow us to compare algorithms and problems meaningfully, and that is the point of the Lab&rsquo;s <a href="#solution-matrix">Solution Matrix</a>.</p>

<p>We now describe the evaluation metrics for <strong>problems</strong> and <strong>algorithms</strong>.</p>

<h3 id="problem-evaluation-metrics">Problem Evaluation Metrics</h3>

<p>problem x {algorithms} ~ solutions</p>

<p>fitness score on 4 parts:
stability and reproducibility (solve ratio),
speed (min episodes),
potential (max reward),
square for granularity</p>
<pre class="highlight plaintext"><code>mean_rewards_per_epi * (1+solved_ratio_of_sessions)**2

ideal_mean_rewards_per_epi = mean_rewards / (epi/solved_epi_speedup)
ideal_solved_ratio = 1
ideal_fitness_score = fitness_score(
    ideal_mean_rewards_per_epi, ideal_solved_ratio)
return ideal_fitness_score
</code></pre>
<h3 id="algorithm-evaluation-metrics">Algorithm Evaluation Metrics</h3>

<p>algorithm x {problems} ~ cross-solutions</p>

          <h1 id="best-solutions"><a name="solutions"></a>Best Solutions</h1>

<p>Algorithms and best solutions by OpenAI Lab users. We want people to start from working solutions instead of stumbling their ways there.</p>

<h2 id="submission-instructions">Submission instructions</h2>

<p>If you invent a new algorithm/combination that beats the best solutions, please submit a <a href="https://github.com/kengz/openai_lab/pulls">Pull Request</a> to the OpenAI Lab.</p>

<p>Refer to the <a href="https://github.com/kengz/openai_lab/blob/master/.github/PULL_REQUEST_TEMPLATE.md">PR template</a> for the submission guideline. See some previous example <a href="https://github.com/kengz/openai_lab/pulls?q=is%3Apr+label%3Asolution+is%3Aclosed">solution PRs</a>.</p>

<h2 id="solution-matrix"><a name="solution-matrix"></a>Solution Matrix</h2>

<p>A matrix of the best <code class="prettyprint">fitness_score</code> of <strong>Algorithms</strong> v.s. <strong>Problems</strong>. The list of accepted solutions can be seen in the <a href="https://github.com/kengz/openai_lab/pulls?q=is%3Apr+label%3Asolution+is%3Aclosed">solution PRs</a></p>

<table><thead>
<tr>
<th style="text-align: left"></th>
<th style="text-align: left">DQN</th>
<th style="text-align: left">double-DQN</th>
<th style="text-align: left">SARSA</th>
<th style="text-align: left">DDPG</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left"><strong>CartPole-v0</strong></td>
<td style="text-align: left"><a href="https://github.com/kengz/openai_lab/pull/73">5.305995</a></td>
<td style="text-align: left"><a href="https://github.com/kengz/openai_lab/pull/78">5.658951</a></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>CartPole-v1</strong></td>
<td style="text-align: left"><a href="https://github.com/kengz/openai_lab/pull/80">7.678957</a></td>
<td style="text-align: left"><a href="https://github.com/kengz/openai_lab/pull/82">9.089594</a></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>Acrobot-v1</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>MountainCar-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>MountainCarContinuous-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>Pendulum-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>LunarLander-v2</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>LunarLanderContinuous-v2</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>BipedalWalker-v2</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>BipedalWalkerHardcore-v2</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>CarRacing-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>AirRaid-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>Alien-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>Assault-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>Breakout-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>MsPacman-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>Pong-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>Qbert-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>SpaceInvader-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>FlappyBird-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><strong>Snake-v0</strong></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
</tbody></table>

<h2 id="algorithms">Algorithms</h2>

<p>The status of the algorithms in OpenAI Lab. Feel free to invent new ones!</p>

<p><em>Pending: we still need a way to cross-evaluate algorithms. Refer to the NEC paper. Perhaps use Normalized human scores per episode vs Millions of Frames.</em></p>

<table><thead>
<tr>
<th style="text-align: left">algorithm</th>
<th style="text-align: left">implemented?</th>
<th style="text-align: left">eval score</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left"><a href="https://arxiv.org/abs/1312.5602">DQN</a></td>
<td style="text-align: left">âœ“</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://arxiv.org/abs/1509.06461">double-DQN</a></td>
<td style="text-align: left">âœ“</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://arxiv.org/abs/1511.06581">dueling-DQN</a></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">SARSA</td>
<td style="text-align: left">âœ“</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://arxiv.org/abs/1511.05952">prioritized replay</a></td>
<td style="text-align: left">in-progress</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">Q*(lambda)</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">Retrace(lambda)</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://en.wikipedia.org/wiki/Cross-entropy_method">CEM (Cross Entropy Method)</a></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://webdocs.cs.ualberta.ca/~sutton/papers/SMSM-NIPS99.pdf">PG (Policy Gradient)</a></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><a href="http://jmlr.org/proceedings/papers/v32/silver14.pdf">DPG (Deterministic Policy Gradient aka actor-critic)</a></td>
<td style="text-align: left">in-progress</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://arxiv.org/abs/1509.02971">DDPG (Deep-DPG, aka actor-critic with target networks)</a></td>
<td style="text-align: left">in-progress</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://arxiv.org/pdf/1602.01783.pdf">A3C (asynchronous advantage actor-critic)</a></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://arxiv.org/abs/1502.05477">TRPO</a></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://arxiv.org/abs/1703.01988">Neural Episodic Control (NEC)</a></td>
<td style="text-align: left">next</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left"><a href="https://arxiv.org/abs/1612.00796">EWC (Elastic Weight Consolidation)</a></td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
</tbody></table>

<h2 id="problems">Problems</h2>

<p>The list of accepted solutions can be seen in the <a href="https://github.com/kengz/openai_lab/pulls?q=is%3Apr+label%3Asolution+is%3Aclosed">solution PRs</a></p>

<h3 id="classic-problems">Classic Problems</h3>

<table><thead>
<tr>
<th style="text-align: left">problem</th>
<th style="text-align: left">fitness score</th>
<th style="text-align: left">epis before solve / best 100-epi mean</th>
<th style="text-align: left">author</th>
<th style="text-align: left">experiment_spec</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left">CartPole-v0</td>
<td style="text-align: left"><a href="https://github.com/kengz/openai_lab/pull/78">5.658951</a></td>
<td style="text-align: left">7</td>
<td style="text-align: left">kengz/lgraesser</td>
<td style="text-align: left">double_dqn</td>
</tr>
<tr>
<td style="text-align: left">CartPole-v1</td>
<td style="text-align: left"><a href="https://github.com/kengz/openai_lab/pull/82">9.089594</a></td>
<td style="text-align: left">16</td>
<td style="text-align: left">kengz/lgraesser</td>
<td style="text-align: left">double_dqn_v1</td>
</tr>
<tr>
<td style="text-align: left">Acrobot-v1</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">MountainCar-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">MountainCarContinuous-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">Pendulum-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
</tbody></table>

<h3 id="box2d-problems">Box2D Problems</h3>

<table><thead>
<tr>
<th style="text-align: left">problem</th>
<th style="text-align: left">fitness score</th>
<th style="text-align: left">epis before solve / best 100-epi mean</th>
<th style="text-align: left">author</th>
<th style="text-align: left">experiment_spec</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left">LunarLander-v2</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">LunarLanderContinuous-v2</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">BipedalWalker-v2</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">BipedalWalkerHardcore-v2</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">CarRacing-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
</tbody></table>

<h3 id="atari-problems">Atari Problems</h3>

<table><thead>
<tr>
<th style="text-align: left">problem</th>
<th style="text-align: left">fitness score</th>
<th style="text-align: left">epis before solve / best 100-epi mean</th>
<th style="text-align: left">author</th>
<th style="text-align: left">experiment_spec</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left">AirRaid-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">Alien-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">Assault-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">Breakout-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">MsPacman-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">Pong-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">Qbert-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">SpaceInvader-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
</tbody></table>

<h3 id="pygame-problems">PyGame Problems</h3>

<table><thead>
<tr>
<th style="text-align: left">problem</th>
<th style="text-align: left">fitness score</th>
<th style="text-align: left">epis before solve / best 100-epi mean</th>
<th style="text-align: left">author</th>
<th style="text-align: left">experiment_spec</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left">FlappyBird-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
<tr>
<td style="text-align: left">Snake-v0</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
</tbody></table>

<h3 id="universe-problems">Universe Problems</h3>

<table><thead>
<tr>
<th style="text-align: left">problem</th>
<th style="text-align: left">fitness score</th>
<th style="text-align: left">epis before solve / best 100-epi mean</th>
<th style="text-align: left">author</th>
<th style="text-align: left">experiment_spec</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
<td style="text-align: left">-</td>
</tr>
</tbody></table>

          <h1 id="development"><a name="development"></a>Development</h1>

<p>(pending writeup)</p>

<p>This is still under active development, and documentation is sparse. The main code lives inside <code class="prettyprint">rl/</code>.</p>

<p>The design of the code is clean enough to simply infer how things work by example.</p>

<ul>
<li><code class="prettyprint">data/</code>: data folders grouped per experiment, each of which contains all the graphs per trial sessions, JSON data file per trial, and csv metrics dataframe per run of multiple trials</li>
<li><code class="prettyprint">rl/agent/</code>: custom agents. Refer to <code class="prettyprint">base_agent.py</code> and <code class="prettyprint">dqn.py</code> to build your own</li>
<li><code class="prettyprint">rl/hyperoptimizer/</code>: Hyperparameter optimizers for the Experiments</li>
<li><code class="prettyprint">rl/memory/</code>: RL agent memory classes</li>
<li><code class="prettyprint">rl/optimizer/</code>: RL agent NN optimizer classes</li>
<li><code class="prettyprint">rl/policy/</code>: RL agent policy classes</li>
<li><code class="prettyprint">rl/preprocessor/</code>: RL agent preprocessor (state and memory) classes</li>
<li><code class="prettyprint">rl/spec/</code>: specify new problems and experiment_specs to run experiments for.</li>
<li><code class="prettyprint">rl/analytics.py</code>: the data analytics module for output experiment data</li>
<li><code class="prettyprint">rl/experiment.py</code>: the main high level experiment logic</li>
<li><code class="prettyprint">rl/util.py</code>: Generic util</li>
</ul>

<p>Each run is an <code class="prettyprint">experiment</code> that runs multiple <code class="prettyprint">Trial</code>s (not restricted to the same <code class="prettyprint">experiment_id</code> for future cross-training). Each <code class="prettyprint">Trial</code> runs multiple (by flag <code class="prettyprint">-t</code>) <code class="prettyprint">Session</code>s, so an <code class="prettyprint">trial</code> is a <code class="prettyprint">sess_grid</code>.</p>

<p>Each trial collects the data from its sessions into <code class="prettyprint">trial_data</code>, which is saved to a JSON and as many plots as there are sessions. On the higher level, <code class="prettyprint">experiment</code> analyses the aggregate <code class="prettyprint">trial_data</code> to produce a best-sorted CSV and graphs of the variables (what&rsquo;s changed across experiments) vs outputs.</p>

<h2 id="problem">problem</h2>

<p>simple, the split, how to add. each JSON key is?</p>

<h2 id="agent">Agent</h2>

<h2 id="hyperoptimizer">HyperOptimizer</h2>

<p>use which first: </p>

<h3 id="linesearch">LineSearch</h3>

<h3 id="gridsearch">GridSearch</h3>

<h3 id="randomsearch">RandomSearch</h3>

<h3 id="hyperoptimizer-roadmap">HyperOptimizer Roadmap</h3>

<ul>
<li><a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf">TPE</a></li>
<li><a href="https://github.com/HIPS/Spearmint">Bayesian Optimizer (Spearmint)</a></li>
<li><a href="http://www.cs.ubc.ca/labs/beta/Projects/SMAC/#software">SMAC</a>.</li>
</ul>

<h3 id="implementation-guideline">Implementation Guideline</h3>

<p>All implemented hyperoptimizers shall extend the base <code class="prettyprint">HyperOptimizer</code> class in <code class="prettyprint">rl/hyperoptimizer/base_hyperoptimizer.py</code> and follow its design for compatibility. Below we show this design to be general theoretically and practically. Moreover, do not use bloated dependencies.</p>

<p><strong>Theoretical design:</strong></p>

<p>A hyperoptimizer is a function <code class="prettyprint">h</code> that takes:</p>

<ul>
<li>a trial (objective) function <code class="prettyprint">Trial</code></li>
<li>a parameter space <code class="prettyprint">P</code> (implemented in <code class="prettyprint">experiment_spec</code>)</li>
</ul>

<p>and runs the algorithm:</p>

<ol>
<li>search the next <code class="prettyprint">p</code> in <code class="prettyprint">P</code> using its internal search algorithm, add to its internal <code class="prettyprint">param_search_list</code></li>
<li>run a (slow) function <code class="prettyprint">Trial(p) = fitness_score</code> (inside trial data)</li>
<li>update search using the feedback <code class="prettyprint">fitness_score</code></li>
<li>repeat until max steps or fitness condition met</li>
</ol>

<p>Note that the search space <code class="prettyprint">P</code> is a tensor space product of <code class="prettyprint">m</code> bounded real spaces <code class="prettyprint">R</code> and <code class="prettyprint">n</code> bounded discrete spaces <code class="prettyprint">N</code>.</p>

<p><strong>Implementation requirements:</strong></p>

<ol>
<li>we want order-preserving and persistence in search for the ability to resume/reproduce an experiment.</li>
<li>the search algorithm may have its own internal memory/belief to facilitate search.</li>
<li>the Trial function shall be treated as a blackbox <code class="prettyprint">Trial(p) = fitness_score</code> with input/output <code class="prettyprint">(p, fitness_score)</code> for the generality of implementation/</li>
</ol>

<p><strong>Specification of search space:</strong></p>

<p>1. for real variable, specify a distribution (an interval is just a uniformly distributed space). specify in <code class="prettyprint">experiment_grid.param</code> like so:</p>
<pre class="highlight json"><code><span class="s2">"lr"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="s2">"min"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0005</span><span class="p">,</span><span class="w">
  </span><span class="s2">"max"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.05</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
<p>2. for discrete variable, specify a list of the values to search over (since it is finite anyway). specify in <code class="prettyprint">experiment_grid.param</code> like so:</p>
<pre class="highlight json"><code><span class="s2">"lr"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span><span class="w"> </span><span class="mf">0.02</span><span class="p">,</span><span class="w"> </span><span class="mf">0.05</span><span class="p">,</span><span class="w"> </span><span class="mf">0.1</span><span class="p">,</span><span class="w"> </span><span class="mf">0.2</span><span class="p">]</span><span class="w">
</span></code></pre>
<p>The hyperopt implementation shall be able to take these 2 types of specs and construct its search space.</p>

<p>Note that whether a variable is real or discrete can be up to the author; some variable such as <code class="prettyprint">lr</code> can be sampled from interval <code class="prettyprint">0.001 to 0.1</code> or human-specified options <code class="prettyprint">[0.01, 0.02, 0.05, 0.1, 0.2]</code>. One way may be more efficient than the other depending on the search algorithm.</p>

<p>The experiment will run it as:</p>
<pre class="highlight python"><code><span class="c"># specify which hyperoptimizer class to use in spec for bookkeeping</span>
<span class="n">Hopt</span> <span class="o">=</span> <span class="n">get_module</span><span class="p">(</span><span class="n">GREF</span><span class="p">,</span> <span class="n">experiment_spec</span><span class="p">[</span><span class="s">'HyperOptimizer'</span><span class="p">])</span>
<span class="n">hopt</span> <span class="o">=</span> <span class="n">Hopt</span><span class="p">(</span><span class="n">Trial</span><span class="p">,</span> <span class="o">**</span><span class="n">experiment_kwargs</span><span class="p">)</span>
<span class="n">experiment_data</span> <span class="o">=</span> <span class="n">hopt</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</code></pre>
<h2 id="memory">Memory</h2>

<h2 id="optimizer">Optimizer</h2>

<h2 id="policy">Policy</h2>

<h2 id="preprocessor">PreProcessor</h2>

          <h1 id="roadmap"><a name="roadmap"></a>Roadmap</h1>

<p>Check the latest under the <a href="https://github.com/kengz/openai_lab/projects">Github Projects</a></p>

          <h1 id="contributing"><a name="contributing"></a>Contributing</h1>

<h2 id="authors">Authors</h2>

<p><em>Note: we are not affiliated with OpenAI; the OpenAI Lab is not tied to any organizations.</em></p>

<ul>
<li>Wah Loon Keng</li>
<li>Laura Graesser</li>
</ul>

      </div>
      <div class="dark-box">
      </div>
    </div>
  </body>
</html>
